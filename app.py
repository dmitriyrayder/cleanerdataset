import streamlit as st
import pandas as pd
import numpy as np
from st_aggrid import AgGrid, GridOptionsBuilder, JsCode, GridUpdateMode
import plotly.express as px
from datetime import datetime, timedelta
import re

st.set_page_config(page_title="üìä –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö", layout="wide")
st.title("üîç –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö —Å AgGrid")

def validate_email(email):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ email"""
    if pd.isna(email): return False
    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    return bool(re.match(pattern, str(email)))

def validate_phone(phone):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–∞"""
    if pd.isna(phone): return False
    cleaned = re.sub(r'[^\d]', '', str(phone))
    return len(cleaned) >= 10 and len(cleaned) <= 15

def detect_outliers_iqr(series):
    """IQR –≤—ã–±—Ä–æ—Å—ã"""
    Q1, Q3 = series.quantile(0.25), series.quantile(0.75)
    IQR = Q3 - Q1
    return (series < (Q1 - 1.5 * IQR)) | (series > (Q3 + 1.5 * IQR))

def create_quality_report(df):
    """–û—Ç—á–µ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö"""
    report = {
        'total_rows': len(df),
        'total_columns': len(df.columns),
        'memory_usage': df.memory_usage(deep=True).sum() / 1024**2,
        'data_types': df.dtypes.value_counts().to_dict(),
        'missing_values': df.isnull().sum().to_dict(),
        'missing_percentage': (df.isnull().sum() / len(df) * 100).to_dict(),
        'duplicate_rows': df.duplicated().sum(),
        'duplicate_percentage': df.duplicated().sum() / len(df) * 100 if len(df) > 0 else 0
    }
    return report

def check_data_consistency(df):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö"""
    issues = {}
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
    if all(col in df.columns for col in ['Price', 'Qty', 'Sum']):
        df['calc_sum'] = df['Price'] * df['Qty']
        df['sum_error'] = np.abs(df['calc_sum'] - df['Sum']) > 0.01
        issues['math_errors'] = df['sum_error'].sum()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    numeric_cols = ['Price', 'Qty', 'Sum']
    for col in numeric_cols:
        if col in df.columns:
            df[f'{col.lower()}_negative'] = df[col] < 0
            issues[f'{col}_negative'] = df[f'{col.lower()}_negative'].sum()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω—É–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    for col in numeric_cols:
        if col in df.columns:
            df[f'{col.lower()}_zero'] = df[col] == 0
            issues[f'{col}_zero'] = df[f'{col.lower()}_zero'].sum()
    
    return issues

def check_text_quality(df):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–ª–µ–π"""
    text_columns = ['Magazin', 'Adress', 'City', 'Describe', 'Model', 'Segment', 'Art']
    issues = {}
    
    for col in text_columns:
        if col in df.columns:
            # –ü—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            df[f'{col.lower()}_empty'] = df[col].isnull() | (df[col].str.strip() == '')
            issues[f'{col}_empty'] = df[f'{col.lower()}_empty'].sum()
            
            # –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
            df[f'{col.lower()}_suspicious'] = df[col].str.contains(r'[<>{}[\]\\|`~@#$%^&*]', na=False)
            issues[f'{col}_suspicious'] = df[f'{col.lower()}_suspicious'].sum()
            
            # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ/–¥–ª–∏–Ω–Ω—ã–µ
            df[f'{col.lower()}_short'] = df[col].str.len() < 2
            df[f'{col.lower()}_long'] = df[col].str.len() > 100
            issues[f'{col}_short'] = df[f'{col.lower()}_short'].sum()
            issues[f'{col}_long'] = df[f'{col.lower()}_long'].sum()
            
            # –¢–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã (–ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –¥–ª—è —Ç–µ–∫—Å—Ç–∞)
            df[f'{col.lower()}_digits_only'] = df[col].str.match(r'^\d+$', na=False)
            issues[f'{col}_digits_only'] = df[f'{col.lower()}_digits_only'].sum()
            
            # –ü–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Å–∏–º–≤–æ–ª—ã
            df[f'{col.lower()}_repeated'] = df[col].str.contains(r'(.)\1{3,}', na=False)
            issues[f'{col}_repeated'] = df[f'{col.lower()}_repeated'].sum()
    
    return issues

def check_date_quality(df):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç"""
    issues = {}
    if 'Datasales' in df.columns:
        today = datetime.now()
        
        # –ù–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞—Ç—ã
        df['date_invalid'] = df['Datasales'].isnull()
        issues['date_invalid'] = df['date_invalid'].sum()
        
        # –ë—É–¥—É—â–∏–µ –¥–∞—Ç—ã
        df['date_future'] = df['Datasales'] > today
        issues['date_future'] = df['date_future'].sum()
        
        # –°–ª–∏—à–∫–æ–º —Å—Ç–∞—Ä—ã–µ –¥–∞—Ç—ã (>20 –ª–µ—Ç)
        old_threshold = today - timedelta(days=365*20)
        df['date_too_old'] = df['Datasales'] < old_threshold
        issues['date_too_old'] = df['date_too_old'].sum()
        
        # –í—ã—Ö–æ–¥–Ω—ã–µ –¥–Ω–∏ (–ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –¥–ª—è –ø—Ä–æ–¥–∞–∂)
        df['date_weekend'] = df['Datasales'].dt.weekday >= 5
        issues['date_weekend'] = df['date_weekend'].sum()
    
    return issues

def check_business_logic(df):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∏"""
    issues = {}
    
    # –î—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –∫–ª—é—á–µ–≤—ã–º –ø–æ–ª—è–º
    key_fields = ['Magazin', 'Datasales', 'Art', 'Model']
    available_fields = [f for f in key_fields if f in df.columns]
    if len(available_fields) >= 2:
        df['business_duplicate'] = df.duplicated(subset=available_fields, keep=False)
        issues['business_duplicates'] = df['business_duplicate'].sum()
    
    # –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ü–µ–Ω—ã –∏ —Å–µ–≥–º–µ–Ω—Ç–∞
    if all(col in df.columns for col in ['Price', 'Segment']):
        segment_prices = df.groupby('Segment')['Price'].agg(['mean', 'std']).fillna(0)
        df['price_segment_outlier'] = False
        
        for segment in segment_prices.index:
            mask = df['Segment'] == segment
            mean_price = segment_prices.loc[segment, 'mean']
            std_price = segment_prices.loc[segment, 'std']
            
            if std_price > 0:
                z_score = np.abs((df.loc[mask, 'Price'] - mean_price) / std_price)
                df.loc[mask, 'price_segment_outlier'] = z_score > 3
        
        issues['price_segment_outliers'] = df['price_segment_outlier'].sum()
    
    return issues

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–∞–Ω–Ω—ã—Ö", type=["xlsx", "xls", "csv"])

if uploaded_file:
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file, encoding='utf-8')
        else:
            df = pd.read_excel(uploaded_file)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç
        if 'Datasales' in df.columns:
            df['Datasales'] = pd.to_datetime(df['Datasales'], errors='coerce')
        
        st.success("‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        
        # === –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –ê–ù–ê–õ–ò–¢–ò–ö–ê ===
        st.header("üìä –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞")
        
        quality_report = create_quality_report(df)
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("üìä –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫", quality_report['total_rows'])
        with col2:
            st.metric("üìã –ö–æ–ª–æ–Ω–æ–∫", quality_report['total_columns'])
        with col3:
            st.metric("üíæ –†–∞–∑–º–µ—Ä (MB)", f"{quality_report['memory_usage']:.2f}")
        with col4:
            st.metric("üîÑ –î—É–±–ª–∏–∫–∞—Ç—ã", f"{quality_report['duplicate_rows']} ({quality_report['duplicate_percentage']:.1f}%)")
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–ª–æ–Ω–æ–∫
        st.subheader("üîç –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º")
        
        column_stats = []
        for col in df.columns:
            stats = {
                '–ö–æ–ª–æ–Ω–∫–∞': col,
                '–¢–∏–ø': str(df[col].dtype),
                '–ü—Ä–æ–ø—É—Å–∫–∏': df[col].isnull().sum(),
                '–ü—Ä–æ–ø—É—Å–∫–∏ %': f"{df[col].isnull().sum() / len(df) * 100:.1f}%",
                '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö': df[col].nunique(),
                '–î—É–±–ª–∏–∫–∞—Ç–æ–≤': df[col].duplicated().sum()
            }
            
            if df[col].dtype in ['int64', 'float64']:
                stats.update({
                    '–ú–∏–Ω': df[col].min(),
                    '–ú–∞–∫—Å': df[col].max(),
                    '–°—Ä–µ–¥–Ω–µ–µ': f"{df[col].mean():.2f}",
                    '–ú–µ–¥–∏–∞–Ω–∞': f"{df[col].median():.2f}",
                    '–°—Ç–¥.–æ—Ç–∫–ª': f"{df[col].std():.2f}"
                })
            elif df[col].dtype == 'object':
                lengths = df[col].str.len()
                stats.update({
                    '–ú–∏–Ω –¥–ª–∏–Ω–∞': lengths.min() if not lengths.empty else 0,
                    '–ú–∞–∫—Å –¥–ª–∏–Ω–∞': lengths.max() if not lengths.empty else 0,
                    '–°—Ä–µ–¥ –¥–ª–∏–Ω–∞': f"{lengths.mean():.1f}" if not lengths.empty else "0",
                    '–ü—É—Å—Ç—ã–µ': (df[col] == '').sum()
                })
            
            column_stats.append(stats)
        
        stats_df = pd.DataFrame(column_stats)
        st.dataframe(stats_df, use_container_width=True)
        
        # === –ü–†–û–í–ï–†–ö–ò –ö–ê–ß–ï–°–¢–í–ê ===
        st.header("üîç –ü—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        required_cols = ['Magazin', 'Datasales', 'Describe', 'Model', 'Segment', 'Price', 'Qty', 'Sum']
        missing_required = [col for col in required_cols if col not in df.columns]
        
        if missing_required:
            st.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(missing_required)}")
        else:
            st.success("‚úÖ –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
        
        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫
        consistency_issues = check_data_consistency(df)
        text_issues = check_text_quality(df)
        date_issues = check_date_quality(df)
        business_issues = check_business_logic(df)
        
        # –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        st.subheader("üßÆ –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("‚ùå –û—à–∏–±–∫–∏ —Å—É–º–º", consistency_issues.get('math_errors', 0))
            st.metric("‚ûñ –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ —Ü–µ–Ω—ã", consistency_issues.get('Price_negative', 0))
        with col2:
            st.metric("‚ûñ –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª-–≤–∞", consistency_issues.get('Qty_negative', 0))
            st.metric("‚ûñ –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ —Å—É–º–º—ã", consistency_issues.get('Sum_negative', 0))
        with col3:
            st.metric("0Ô∏è‚É£ –ù—É–ª–µ–≤—ã–µ —Ü–µ–Ω—ã", consistency_issues.get('Price_zero', 0))
            st.metric("0Ô∏è‚É£ –ù—É–ª–µ–≤—ã–µ –∫–æ–ª-–≤–∞", consistency_issues.get('Qty_zero', 0))
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∏ –¥–∞—Ç
        if date_issues:
            st.subheader("üìÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("‚ùå –ù–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ", date_issues.get('date_invalid', 0))
            with col2:
                st.metric("üîÆ –ë—É–¥—É—â–∏–µ –¥–∞—Ç—ã", date_issues.get('date_future', 0))
            with col3:
                st.metric("üìú –°–ª–∏—à–∫–æ–º —Å—Ç–∞—Ä—ã–µ", date_issues.get('date_too_old', 0))
            with col4:
                st.metric("üìÖ –í—ã—Ö–æ–¥–Ω—ã–µ –¥–Ω–∏", date_issues.get('date_weekend', 0))
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∏ —Ç–µ–∫—Å—Ç–∞
        st.subheader("üìù –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–ª–µ–π")
        text_cols = ['Magazin', 'Adress', 'City', 'Describe', 'Model', 'Segment']
        
        for col in text_cols:
            if col in df.columns:
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric(f"üóëÔ∏è {col}: –ø—É—Å—Ç—ã–µ", text_issues.get(f'{col}_empty', 0))
                with col2:
                    st.metric(f"‚ö†Ô∏è {col}: –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ", text_issues.get(f'{col}_suspicious', 0))
                with col3:
                    st.metric(f"üìè {col}: –∫–æ—Ä–æ—Ç–∫–∏–µ", text_issues.get(f'{col}_short', 0))
                with col4:
                    st.metric(f"üî¢ {col}: —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã", text_issues.get(f'{col}_digits_only', 0))
        
        # –ë–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∞
        if business_issues:
            st.subheader("üíº –ë–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∞")
            col1, col2 = st.columns(2)
            with col1:
                st.metric("üîÑ –ë–∏–∑–Ω–µ—Å-–¥—É–±–ª–∏–∫–∞—Ç—ã", business_issues.get('business_duplicates', 0))
            with col2:
                st.metric("üí∞ –ê–Ω–æ–º–∞–ª–∏–∏ —Ü–µ–Ω–∞-—Å–µ–≥–º–µ–Ω—Ç", business_issues.get('price_segment_outliers', 0))
        
        # –ü–æ–¥—Å—á–µ—Ç –≤—Å–µ—Ö –ø—Ä–æ–±–ª–µ–º
        problem_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in 
                       ['error', 'negative', 'zero', 'future', 'old', 'invalid', 'suspicious', 
                        'short', 'long', 'digits_only', 'repeated', 'weekend', 'duplicate', 'outlier', 'empty'])]
        
        if problem_cols:
            df['total_problems'] = df[problem_cols].sum(axis=1)
            
            st.subheader("üìã –°–≤–æ–¥–∫–∞ –ø—Ä–æ–±–ª–µ–º")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("üìä –°—Ç—Ä–æ–∫ —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏", (df['total_problems'] > 0).sum())
            with col2:
                st.metric("‚úÖ –ß–∏—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫", (df['total_problems'] == 0).sum())
            with col3:
                quality_pct = (df['total_problems'] == 0).sum() / len(df) * 100
                st.metric("üìà –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö", f"{quality_pct:.1f}%")
            
            # –ì—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–±–ª–µ–º
            problem_counts = df[problem_cols].sum().sort_values(ascending=False).head(15)
            if not problem_counts.empty:
                fig = px.bar(
                    x=problem_counts.values,
                    y=problem_counts.index,
                    orientation='h',
                    title="–¢–æ–ø-15 —Ç–∏–ø–æ–≤ –ø—Ä–æ–±–ª–µ–º –≤ –¥–∞–Ω–Ω—ã—Ö"
                )
                st.plotly_chart(fig, use_container_width=True)
        
        # === AgGrid ===
        st.header("üìã –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ AgGrid
        gb = GridOptionsBuilder.from_dataframe(df)
        gb.configure_default_column(editable=True, filter=True, sortable=True, resizable=True)
        
        # –°—Ç–∏–ª–∏ –¥–ª—è —Ä–∞—Å–∫—Ä–∞—Å–∫–∏ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å—Ç—Ä–æ–∫
        cell_style = JsCode("""
        function(params) {
            const data = params.data;
            if (data.sum_error || data.price_negative || data.qty_negative || data.sum_negative) {
                return { backgroundColor: '#ffcccc' };
            }
            if (data.date_invalid || data.date_future) {
                return { backgroundColor: '#ffe6cc' };
            }
            if (data.magazin_empty || data.describe_empty || data.model_empty) {
                return { backgroundColor: '#fff2cc' };
            }
            if (data.magazin_suspicious || data.describe_suspicious) {
                return { backgroundColor: '#cce6ff' };
            }
            return null;
        }
        """)
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—Ç–∏–ª–µ–π –∫ –æ—Å–Ω–æ–≤–Ω—ã–º –∫–æ–ª–æ–Ω–∫–∞–º
        main_cols = ['Magazin', 'Adress', 'City', 'Datasales', 'Art', 'Describe', 'Model', 'Segment', 'Price', 'Qty', 'Sum']
        for col in main_cols:
            if col in df.columns:
                gb.configure_column(col, cellStyle=cell_style)
        
        # –°–∫—Ä—ã—Ç–∏–µ —Å–ª—É–∂–µ–±–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        service_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in 
                       ['error', 'negative', 'zero', 'invalid', 'suspicious', 'empty', 'short', 'long', 'calc'])]
        for col in service_cols:
            gb.configure_column(col, hide=True)
        
        gb.configure_grid_options(domLayout='normal', pagination=True, paginationPageSize=50)
        gb.configure_selection(selection_mode="multiple", use_checkbox=True)
        
        # –õ–µ–≥–µ–Ω–¥–∞
        st.markdown("""
        **–¶–≤–µ—Ç–æ–≤–∞—è —Å—Ö–µ–º–∞:**
        - üî¥ –ö—Ä–∞—Å–Ω—ã–π: –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏
        - üü† –û—Ä–∞–Ω–∂–µ–≤—ã–π: –ø—Ä–æ–±–ª–µ–º—ã —Å –¥–∞—Ç–∞–º–∏  
        - üü° –ñ–µ–ª—Ç—ã–π: –ø—É—Å—Ç—ã–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
        - üîµ –ì–æ–ª—É–±–æ–π: –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        """)
        
        grid_response = AgGrid(
            df,
            gridOptions=gb.build(),
            height=500,
            update_mode=GridUpdateMode.VALUE_CHANGED,
            fit_columns_on_grid_load=True,
            allow_unsafe_jscode=True,
            theme="alpine"
        )
        
        updated_df = pd.DataFrame(grid_response['data'])
        
        # === –≠–ö–°–ü–û–†–¢ ===
        st.header("üì§ –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # –í—Å–µ –¥–∞–Ω–Ω—ã–µ
            csv_all = updated_df.to_csv(index=False)
            st.download_button("‚¨áÔ∏è –í—Å–µ –¥–∞–Ω–Ω—ã–µ", csv_all, "all_data.csv", "text/csv")
        
        with col2:
            # –ß–∏—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ
            if 'total_problems' in updated_df.columns:
                clean_data = updated_df[updated_df['total_problems'] == 0]
                clean_cols = [col for col in main_cols if col in clean_data.columns]
                csv_clean = clean_data[clean_cols].to_csv(index=False)
                st.download_button("‚úÖ –ß–∏—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ", csv_clean, "clean_data.csv", "text/csv")
        
        with col3:
            # –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            if 'total_problems' in updated_df.columns:
                problem_data = updated_df[updated_df['total_problems'] > 0]
                if not problem_data.empty:
                    csv_problems = problem_data.to_csv(index=False)
                    st.download_button("‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ", csv_problems, "problems.csv", "text/csv")
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        st.subheader("üìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ", len(updated_df))
        with col2:
            if 'total_problems' in updated_df.columns:
                clean_count = (updated_df['total_problems'] == 0).sum()
                st.metric("‚úÖ –ß–∏—Å—Ç—ã—Ö", clean_count)
        with col3:
            if 'total_problems' in updated_df.columns:
                problem_count = (updated_df['total_problems'] > 0).sum()
                st.metric("‚ö†Ô∏è –° –ø—Ä–æ–±–ª–µ–º–∞–º–∏", problem_count)
        with col4:
            if 'total_problems' in updated_df.columns:
                quality = (updated_df['total_problems'] == 0).sum() / len(updated_df) * 100
                st.metric("üéØ –ö–∞—á–µ—Å—Ç–≤–æ", f"{quality:.1f}%")
        
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")

else:
    st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    st.markdown("""
    **–û–∂–∏–¥–∞–µ–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏:**
    - `Magazin` - –Ω–∞–∑–≤–∞–Ω–∏–µ –º–∞–≥–∞–∑–∏–Ω–∞
    - `Adress` - –∞–¥—Ä–µ—Å –º–∞–≥–∞–∑–∏–Ω–∞  
    - `City` - –≥–æ—Ä–æ–¥
    - `Datasales` - –¥–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏
    - `Art` - –∞—Ä—Ç–∏–∫—É–ª —Ç–æ–≤–∞—Ä–∞
    - `Describe` - –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
    - `Model` - –º–æ–¥–µ–ª—å —Ç–æ–≤–∞—Ä–∞
    - `Segment` - —Å–µ–≥–º–µ–Ω—Ç —Ç–æ–≤–∞—Ä–∞
    - `Price` - —Ü–µ–Ω–∞ –∑–∞ –µ–¥–∏–Ω–∏—Ü—É
    - `Qty` - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    - `Sum` - –æ–±—â–∞—è —Å—É–º–º–∞
    """)
