import streamlit as st
import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
from st_aggrid import AgGrid, GridOptionsBuilder, JsCode, GridUpdateMode
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import re

st.set_page_config(page_title="üìä –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö", layout="wide")
st.title("üß† ML + AgGrid: –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö")

def validate_email(email):
    if pd.isna(email): return False
    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    return bool(re.match(pattern, str(email)))

def validate_phone(phone):
    if pd.isna(phone): return False
    cleaned = re.sub(r'[^\d]', '', str(phone))
    return len(cleaned) >= 10 and len(cleaned) <= 15

def validate_address(address):
    if pd.isna(address): return False
    addr_str = str(address).strip()
    return len(addr_str) >= 5 and any(char.isdigit() for char in addr_str)

def validate_city(city):
    if pd.isna(city): return False
    city_str = str(city).strip()
    return len(city_str) >= 2 and city_str.replace(' ', '').isalpha()

def detect_outliers_iqr(series):
    Q1, Q3 = series.quantile(0.25), series.quantile(0.75)
    IQR = Q3 - Q1
    return (series < Q1 - 1.5 * IQR) | (series > Q3 + 1.5 * IQR)

def create_comprehensive_report(df):
    report = {
        'total_rows': len(df), 'total_columns': len(df.columns),
        'memory_usage': df.memory_usage(deep=True).sum() / 1024**2,
        'data_types': df.dtypes.value_counts().to_dict(),
        'missing_values': df.isnull().sum().to_dict(),
        'missing_percentage': (df.isnull().sum() / len(df) * 100).to_dict(),
        'duplicate_rows': df.duplicated().sum(),
        'duplicate_percentage': df.duplicated().sum() / len(df) * 100,
        'completely_empty_rows': (df.isnull().all(axis=1)).sum(),
        'rows_with_missing': (df.isnull().any(axis=1)).sum()
    }
    return report

uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–∞–Ω–Ω—ã—Ö", type=["xlsx", "xls", "csv"])

if uploaded_file:
    try:
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file, encoding='utf-8')
        else:
            df = pd.read_excel(uploaded_file)
        
        # –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç
        if 'Datasales' in df.columns:
            try:
                df['Datasales'] = pd.to_datetime(df['Datasales'], errors='coerce')
            except:
                st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –¥–∞—Ç—ã")
        
        st.success("‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
        
        # === –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –ê–ù–ê–õ–ò–¢–ò–ö–ê ===
        st.header("üìà –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞")
        quality_report = create_comprehensive_report(df)
        
        col1, col2, col3, col4, col5 = st.columns(5)
        with col1:
            st.metric("üìä –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫", quality_report['total_rows'])
        with col2:
            st.metric("üìã –ö–æ–ª–æ–Ω–æ–∫", quality_report['total_columns'])
        with col3:
            st.metric("üíæ –†–∞–∑–º–µ—Ä", f"{quality_report['memory_usage']:.1f} MB")
        with col4:
            st.metric("üîÑ –î—É–±–ª–∏–∫–∞—Ç—ã", f"{quality_report['duplicate_rows']}")
        with col5:
            st.metric("üï≥Ô∏è –ü—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏", f"{quality_report['completely_empty_rows']}")
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–ª–æ–Ω–æ–∫
        st.subheader("üîç –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º")
        column_analysis = []
        for col in df.columns:
            analysis = {
                '–ö–æ–ª–æ–Ω–∫–∞': col, '–¢–∏–ø': str(df[col].dtype),
                '–ü—Ä–æ–ø—É—â–µ–Ω–æ': df[col].isnull().sum(),
                '–ü—Ä–æ–ø—É—â–µ–Ω–æ %': f"{df[col].isnull().sum() / len(df) * 100:.1f}%",
                '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö': df[col].nunique(),
                '–î—É–±–ª–∏–∫–∞—Ç–æ–≤': df[col].duplicated().sum()
            }
            
            if df[col].dtype in ['int64', 'float64']:
                analysis.update({
                    '–ú–∏–Ω': df[col].min(), '–ú–∞–∫—Å': df[col].max(),
                    '–°—Ä–µ–¥–Ω–µ–µ': f"{df[col].mean():.2f}",
                    '–ú–µ–¥–∏–∞–Ω–∞': f"{df[col].median():.2f}",
                    '–°—Ç–¥.–æ—Ç–∫–ª': f"{df[col].std():.2f}"
                })
            elif df[col].dtype == 'object':
                lens = df[col].str.len()
                analysis.update({
                    '–ú–∏–Ω –¥–ª–∏–Ω–∞': lens.min() if not df[col].empty else 0,
                    '–ú–∞–∫—Å –¥–ª–∏–Ω–∞': lens.max() if not df[col].empty else 0,
                    '–°—Ä.–¥–ª–∏–Ω–∞': f"{lens.mean():.1f}" if not df[col].empty else "0",
                    '–ü—É—Å—Ç—ã–µ': (df[col] == '').sum()
                })
            column_analysis.append(analysis)
        
        st.dataframe(pd.DataFrame(column_analysis), use_container_width=True)
        
        # === –ü–†–û–í–ï–†–ö–ò –ö–ê–ß–ï–°–¢–í–ê ===
        st.header("üîç –ü—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        required_cols = ['Magazin', 'Adress', 'City', 'Datasales', 'Describe', 'Model', 'Segment', 'Price', 'Qty', 'Sum']
        missing_cols = [col for col in required_cols if col not in df.columns]
        
        if missing_cols:
            st.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {', '.join(missing_cols)}")
        else:
            st.success("‚úÖ –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
        
        # –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        if all(col in df.columns for col in ['Price', 'Qty', 'Sum']):
            df['calc_sum'] = df['Price'] * df['Qty']
            df['sum_error'] = np.abs(df['calc_sum'] - df['Sum']) > 1e-2
            df['negative_price'] = df['Price'] < 0
            df['negative_qty'] = df['Qty'] < 0
            df['negative_sum'] = df['Sum'] < 0
            df['zero_price'] = df['Price'] == 0
            df['zero_qty'] = df['Qty'] == 0
            df['unrealistic_price'] = df['Price'] > 1000000
            df['unrealistic_qty'] = df['Qty'] > 10000
            
            st.subheader("üßÆ –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("‚ùå –û—à–∏–±–∫–∏ —Å—É–º–º—ã", df['sum_error'].sum())
                st.metric("‚ûñ –û—Ç—Ä–∏—Ü. —Ü–µ–Ω—ã", df['negative_price'].sum())
            with col2:
                st.metric("‚ûñ –û—Ç—Ä–∏—Ü. –∫–æ–ª-–≤–æ", df['negative_qty'].sum())
                st.metric("‚ûñ –û—Ç—Ä–∏—Ü. —Å—É–º–º—ã", df['negative_sum'].sum())
            with col3:
                st.metric("0Ô∏è‚É£ –ù—É–ª–µ–≤—ã–µ —Ü–µ–Ω—ã", df['zero_price'].sum())
                st.metric("0Ô∏è‚É£ –ù—É–ª–µ–≤—ã–µ –∫–æ–ª-–≤–∞", df['zero_qty'].sum())
            with col4:
                st.metric("üí∞ –ù–µ—Ä–µ–∞–ª—å–Ω—ã–µ —Ü–µ–Ω—ã", df['unrealistic_price'].sum())
                st.metric("üì¶ –ù–µ—Ä–µ–∞–ª—å–Ω—ã–µ –∫–æ–ª-–≤–∞", df['unrealistic_qty'].sum())
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç
        if 'Datasales' in df.columns:
            st.subheader("üìÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç")
            today = datetime.now()
            df['future_date'] = df['Datasales'] > today
            df['old_date'] = df['Datasales'] < (today - timedelta(days=365*5))
            df['invalid_date'] = df['Datasales'].isnull()
            df['weekend_sales'] = df['Datasales'].dt.weekday >= 5
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("üîÆ –ë—É–¥—É—â–∏–µ –¥–∞—Ç—ã", df['future_date'].sum())
            with col2:
                st.metric("üìú –°—Ç–∞—Ä—ã–µ –¥–∞—Ç—ã", df['old_date'].sum())
            with col3:
                st.metric("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–µ –¥–∞—Ç—ã", df['invalid_date'].sum())
            with col4:
                st.metric("üìÖ –í—ã—Ö–æ–¥–Ω—ã–µ", df['weekend_sales'].sum())
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–¥—Ä–µ—Å–æ–≤ –∏ –≥–æ—Ä–æ–¥–æ–≤
        st.subheader("üè† –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–¥—Ä–µ—Å–æ–≤ –∏ –≥–æ—Ä–æ–¥–æ–≤")
        if 'Adress' in df.columns:
            df['invalid_address'] = ~df['Adress'].apply(validate_address)
            df['short_address'] = df['Adress'].str.len() < 5
            df['long_address'] = df['Adress'].str.len() > 100
        
        if 'City' in df.columns:
            df['invalid_city'] = ~df['City'].apply(validate_city)
            df['short_city'] = df['City'].str.len() < 2
            df['numeric_city'] = df['City'].str.isdigit()
        
        col1, col2, col3, col4 = st.columns(4)
        if 'Adress' in df.columns:
            with col1:
                st.metric("üè† –ù–µ–≤–µ—Ä–Ω—ã–µ –∞–¥—Ä–µ—Å–∞", df['invalid_address'].sum())
            with col2:
                st.metric("üìè –ö–æ—Ä–æ—Ç–∫–∏–µ –∞–¥—Ä–µ—Å–∞", df['short_address'].sum())
        if 'City' in df.columns:
            with col3:
                st.metric("üèôÔ∏è –ù–µ–≤–µ—Ä–Ω—ã–µ –≥–æ—Ä–æ–¥–∞", df['invalid_city'].sum())
            with col4:
                st.metric("üî¢ –¶–∏—Ñ—Ä–æ–≤—ã–µ –≥–æ—Ä–æ–¥–∞", df['numeric_city'].sum())
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–ª–µ–π
        st.subheader("üìù –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–ª–µ–π")
        text_cols = ['Magazin', 'Describe', 'Model', 'Segment']
        
        for col in text_cols:
            if col in df.columns:
                df[f'{col}_suspicious'] = df[col].str.contains(r'[<>{}[\]\\|`~@#$%^&*]', na=False)
                df[f'{col}_too_short'] = df[col].str.len() < 2
                df[f'{col}_too_long'] = df[col].str.len() > 100
                df[f'{col}_only_digits'] = df[col].str.isdigit()
                df[f'{col}_special_chars'] = df[col].str.contains(r'[^\w\s\-]', na=False)
        
        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–ª–µ–π
        text_problems = {}
        for col in text_cols:
            if col in df.columns:
                problems = (df[f'{col}_suspicious'].sum() + df[f'{col}_too_short'].sum() + 
                          df[f'{col}_too_long'].sum() + df[f'{col}_only_digits'].sum())
                text_problems[col] = problems
        
        if text_problems:
            col1, col2, col3, col4 = st.columns(4)
            cols = list(text_problems.keys())
            for i, (col, problems) in enumerate(text_problems.items()):
                with [col1, col2, col3, col4][i % 4]:
                    st.metric(f"üìù {col} –ø—Ä–æ–±–ª–µ–º—ã", problems)
        
        # ML-–∞–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π
        st.subheader("ü§ñ ML-–∞–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π")
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        ml_cols = [col for col in numeric_cols if not any(x in col for x in ['calc_', 'sum_', 'negative_', 'zero_', 'unrealistic_'])]
        
        if len(ml_cols) >= 2:
            try:
                X = df[ml_cols].fillna(0)
                if X.shape[1] >= 2:
                    scaler = StandardScaler()
                    X_scaled = scaler.fit_transform(X)
                    
                    # Isolation Forest
                    iso = IsolationForest(contamination=0.05, random_state=42, n_estimators=50)
                    df['ml_anomaly'] = iso.fit_predict(X_scaled) == -1
                    
                    # IQR outliers
                    for col in ['Price', 'Qty', 'Sum']:
                        if col in df.columns:
                            df[f'{col}_outlier'] = detect_outliers_iqr(df[col])
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("üö® ML-–∞–Ω–æ–º–∞–ª–∏–∏", df['ml_anomaly'].sum())
                    with col2:
                        if 'Price_outlier' in df.columns:
                            price_outliers = df['Price_outlier'].sum()
                            st.metric("üí∞ –í—ã–±—Ä–æ—Å—ã —Ü–µ–Ω", price_outliers)
                    with col3:
                        if 'Qty_outlier' in df.columns:
                            qty_outliers = df['Qty_outlier'].sum()
                            st.metric("üì¶ –í—ã–±—Ä–æ—Å—ã –∫–æ–ª-–≤–∞", qty_outliers)
                    
                    st.success("‚úÖ ML-–∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")
                else:
                    df['ml_anomaly'] = False
                    st.warning("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML")
            except Exception as e:
                df['ml_anomaly'] = False
                st.error(f"‚ùå –û—à–∏–±–∫–∞ ML: {str(e)[:50]}")
        else:
            df['ml_anomaly'] = False
            st.warning("‚ö†Ô∏è –ù–µ—Ç —á–∏—Å–ª–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML")
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏
        st.subheader("üîó –ü—Ä–æ–≤–µ—Ä–∫–∏ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ –∫–ª—é—á–µ–≤—ã–º –ø–æ–ª—è–º
        if all(col in df.columns for col in ['Magazin', 'Datasales', 'Art']):
            df['duplicate_transaction'] = df.duplicated(subset=['Magazin', 'Datasales', 'Art'], keep=False)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π –∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        if all(col in df.columns for col in ['Model', 'Segment']):
            model_segment_map = df.groupby('Model')['Segment'].nunique()
            inconsistent_models = model_segment_map[model_segment_map > 1].index
            df['inconsistent_model_segment'] = df['Model'].isin(inconsistent_models)
        
        # –°–≤–æ–¥–∫–∞ –≤—Å–µ—Ö –ø—Ä–æ–±–ª–µ–º
        problem_cols = [col for col in df.columns if any(x in col for x in 
                       ['error', 'negative_', 'zero_', 'future_', 'old_', 'invalid_', 'suspicious', 
                        'too_short', 'too_long', 'only_digits', 'ml_anomaly', 'outlier', 'duplicate_', 'inconsistent'])]
        
        if problem_cols:
            df['total_problems'] = df[problem_cols].sum(axis=1)
            
            st.subheader("üìã –û–±—â–∞—è —Å–≤–æ–¥–∫–∞")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("üìä –°—Ç—Ä–æ–∫ —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏", (df['total_problems'] > 0).sum())
            with col2:
                st.metric("‚úÖ –ß–∏—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫", (df['total_problems'] == 0).sum())
            with col3:
                st.metric("üìà –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö", f"{(df['total_problems'] == 0).sum() / len(df) * 100:.1f}%")
            with col4:
                st.metric("‚ö†Ô∏è –í—Å–µ–≥–æ –ø—Ä–æ–±–ª–µ–º", df[problem_cols].sum().sum())
            
            # –ì—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–±–ª–µ–º
            st.subheader("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º")
            problem_counts = df[problem_cols].sum().sort_values(ascending=False)[:15]
            
            if not problem_counts.empty:
                fig = px.bar(x=problem_counts.values, y=problem_counts.index, orientation='h',
                           title="–¢–æ–ø-15 —Ç–∏–ø–æ–≤ –ø—Ä–æ–±–ª–µ–º", height=400)
                st.plotly_chart(fig, use_container_width=True)
        
        # === AgGrid ===
        st.header("üìã –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ")
        
        gb = GridOptionsBuilder.from_dataframe(df)
        gb.configure_default_column(editable=True, filter=True, sortable=True, resizable=True)
        
        # –£—Å–ª–æ–≤–Ω–∞—è —Ä–∞—Å–∫—Ä–∞—Å–∫–∞
        cell_style = JsCode("""
        function(params) {
            const data = params.data;
            if (data.sum_error || data.negative_price || data.negative_qty) return {backgroundColor: '#ffcccc'};
            if (data.ml_anomaly) return {backgroundColor: '#ffffcc'};
            if (data.future_date || data.invalid_date) return {backgroundColor: '#ffe6cc'};
            if (data.invalid_address || data.invalid_city) return {backgroundColor: '#e6ccff'};
            if (data.Price_outlier || data.Qty_outlier) return {backgroundColor: '#ffccff'};
            return null;
        }
        """)
        
        main_cols = ['Magazin', 'Adress', 'City', 'Datasales', 'Describe', 'Model', 'Segment', 'Price', 'Qty', 'Sum']
        for col in main_cols:
            if col in df.columns:
                gb.configure_column(col, cellStyle=cell_style)
        
        gb.configure_grid_options(domLayout='normal', pagination=True, paginationPageSize=50)
        gb.configure_selection(selection_mode="multiple", use_checkbox=True)
        
        # –õ–µ–≥–µ–Ω–¥–∞
        st.markdown("""
        **üé® –¶–≤–µ—Ç–∞:** üî¥ –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ | üü° ML-–∞–Ω–æ–º–∞–ª–∏–∏ | üü† –ü—Ä–æ–±–ª–µ–º—ã –¥–∞—Ç | üü£ –ê–¥—Ä–µ—Å–∞/–≥–æ—Ä–æ–¥–∞ | üü¢ –í—ã–±—Ä–æ—Å—ã
        """)
        
        grid_response = AgGrid(df, gridOptions=gb.build(), height=500, 
                              update_mode=GridUpdateMode.VALUE_CHANGED,
                              fit_columns_on_grid_load=True, allow_unsafe_jscode=True,
                              theme="alpine")
        
        updated_df = pd.DataFrame(grid_response['data'])
        
        # === –≠–∫—Å–ø–æ—Ä—Ç ===
        st.header("üì§ –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            csv_all = updated_df.to_csv(index=False)
            st.download_button("‚¨áÔ∏è –í—Å–µ –¥–∞–Ω–Ω—ã–µ", csv_all, "all_data_checked.csv", "text/csv")
        
        with col2:
            if 'total_problems' in updated_df.columns:
                clean_data = updated_df[updated_df['total_problems'] == 0]
                clean_cols = [col for col in main_cols if col in clean_data.columns]
                csv_clean = clean_data[clean_cols].to_csv(index=False)
                st.download_button("‚úÖ –ß–∏—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ", csv_clean, "clean_data.csv", "text/csv")
        
        with col3:
            if 'total_problems' in updated_df.columns:
                problem_data = updated_df[updated_df['total_problems'] > 0]
                if not problem_data.empty:
                    csv_problems = problem_data.to_csv(index=False)
                    st.download_button("‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ", csv_problems, "problems.csv", "text/csv")
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        st.subheader("üéØ –ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ", len(updated_df))
        with col2:
            if 'total_problems' in updated_df.columns:
                st.metric("‚úÖ –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö", (updated_df['total_problems'] == 0).sum())
        with col3:
            if 'total_problems' in updated_df.columns:
                st.metric("‚ö†Ô∏è –° –ø—Ä–æ–±–ª–µ–º–∞–º–∏", (updated_df['total_problems'] > 0).sum())
        with col4:
            if 'total_problems' in updated_df.columns:
                quality = (updated_df['total_problems'] == 0).sum() / len(updated_df) * 100
                st.metric("üèÜ –ö–∞—á–µ—Å—Ç–≤–æ", f"{quality:.1f}%")
        
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")

else:
    st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    st.markdown("""
    **üìã –û–∂–∏–¥–∞–µ–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏:**
    - `Magazin` - –Ω–∞–∑–≤–∞–Ω–∏–µ –º–∞–≥–∞–∑–∏–Ω–∞
    - `Adress` - –∞–¥—Ä–µ—Å –º–∞–≥–∞–∑–∏–Ω–∞  
    - `City` - –≥–æ—Ä–æ–¥
    - `Datasales` - –¥–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏
    - `Art` - –∞—Ä—Ç–∏–∫—É–ª —Ç–æ–≤–∞—Ä–∞
    - `Describe` - –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
    - `Model` - –º–æ–¥–µ–ª—å —Ç–æ–≤–∞—Ä–∞
    - `Segment` - —Å–µ–≥–º–µ–Ω—Ç —Ç–æ–≤–∞—Ä–∞
    - `Price` - —Ü–µ–Ω–∞ –∑–∞ –µ–¥–∏–Ω–∏—Ü—É
    - `Qty` - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    - `Sum` - –æ–±—â–∞—è —Å—É–º–º–∞
    
    **üîç –¢–∏–ø—ã –ø—Ä–æ–≤–µ—Ä–æ–∫:**
    - –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å (Price √ó Qty = Sum)
    - –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞—Ç (–±—É–¥—É—â–∏–µ/—Å—Ç–∞—Ä—ã–µ –¥–∞—Ç—ã)
    - –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–¥—Ä–µ—Å–æ–≤ –∏ –≥–æ—Ä–æ–¥–æ–≤
    - ML-–¥–µ—Ç–µ–∫—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π
    - –ü–æ–∏—Å–∫ –≤—ã–±—Ä–æ—Å–æ–≤ –∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    - –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–ª–µ–π
    """)
