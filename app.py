import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import plotly.graph_objects as go
import plotly.express as px
try:
    from sklearn.ensemble import IsolationForest
    from sklearn.svm import OneClassSVM
    from sklearn.preprocessing import StandardScaler
except ImportError:
    st.error("–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏...")
    import subprocess
    subprocess.check_call(["pip", "install", "scikit-learn"])
    from sklearn.ensemble import IsolationForest
    from sklearn.svm import OneClassSVM
    from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(page_title="–ü—Ä–æ–≥–Ω–æ–∑ –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ –ü—Ä–æ–¥–∞–∂", layout="wide", page_icon="üìä")

# –°—Ç–∏–ª–∏
st.markdown("""
<style>
.metric-card {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    padding: 20px;
    border-radius: 10px;
    color: white;
    text-align: center;
}
.alert-high { background-color: #ff4444; padding: 10px; border-radius: 5px; color: white; }
.alert-medium { background-color: #ffaa00; padding: 10px; border-radius: 5px; color: white; }
.alert-low { background-color: #00cc44; padding: 10px; border-radius: 5px; color: white; }
</style>
""", unsafe_allow_html=True)

# –§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö
@st.cache_data
def generate_fake_data(n_records=5000):
    np.random.seed(42)
    
    # –í—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω
    start_date = datetime(2022, 1, 1)
    dates = [start_date + timedelta(days=i) for i in range(n_records)]
    
    # –ú–∞–≥–∞–∑–∏–Ω—ã
    stores = [f"–ú–∞–≥–∞–∑–∏–Ω_{i:02d}" for i in range(1, 41)]
    
    # –ë—Ä–µ–Ω–¥—ã –∏ —Ç–æ–≤–∞—Ä—ã
    brands = ['VPL', 'RAY-BAN', "HUMPHREY'S", '–î—Ä—É–≥–∏–µ']
    articles = ['403013', '519319', '1336266', '1386943', '1492555']
    segments = ['–ü—Ä–µ–º–∏–∞–ª—å–Ω—ã–π —Ç–æ–≤–∞—Ä', '–°—Ä–µ–¥–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç']
    statuses = ['–í —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ', '–†–∞–±–æ—á–∏–π –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç', '–ù–µ–ª–µ–≤—ã–π']
    
    data = []
    for date in dates:
        # –¢—Ä–µ–Ω–¥ + —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å + —à—É–º
        trend = 2000 + (date - start_date).days * 0.5
        seasonality = 500 * np.sin(2 * np.pi * (date.timetuple().tm_yday / 365))
        
        # –°–ª—É—á–∞–π–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏ (10% –¥–Ω–µ–π)
        if np.random.random() < 0.1:
            anomaly = np.random.choice([-800, 800])
        else:
            anomaly = 0
            
        base_price = trend + seasonality + anomaly + np.random.normal(0, 300)
        
        for _ in range(np.random.randint(1, 8)):  # 1-7 –∑–∞–ø–∏—Å–µ–π –≤ –¥–µ–Ω—å
            store = np.random.choice(stores)
            brand = np.random.choice(brands, p=[0.3, 0.25, 0.2, 0.25])
            
            record = {
                'Date': date,
                'Datasales': date,
                'Art': np.random.choice(articles),
                'Describe': f"–û–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ {np.random.randint(1,100)}",
                'Model': brand,
                'Segment': np.random.choice(segments),
                'Status': np.random.choice(statuses),
                'Cycle': '–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª',
                'PriceType': np.random.choice(['–í–∑—Ä–æ—Å–ª—ã–π', '–î–µ—Ç—Å–∫–∏–π', '–ü–∞–¥–µ–Ω–∏–µ']),
                'Markup': np.random.choice([10, 20, 30, 40]) / 100,
                'Brand': brand,
                'ABS': np.random.choice(['A', 'B', 'C']),
                'MatrixType': np.random.choice(['1 –≥–æ—Ä–æ–¥', '–†–µ–≥–∏–æ–Ω—ã', '–ê—É—Ç–ª–µ—Ç']),
                'Price': int(base_price * np.random.uniform(0.8, 1.2)),
                'Qty': np.random.randint(1, 5),
                'Store': store
            }
            record['Sum'] = record['Price'] * record['Qty']
            data.append(record)
    
    return pd.DataFrame(data)

# –§—É–Ω–∫—Ü–∏—è —Ä–∞—Å—á–µ—Ç–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π GARCH)
def calculate_volatility(series, window=7):
    returns = series.pct_change().dropna()
    volatility = returns.rolling(window=window).std() * np.sqrt(window)
    return volatility

# –î–µ—Ç–µ–∫—Ç–æ—Ä –∞–Ω–æ–º–∞–ª–∏–π
def detect_anomalies(df, contamination=0.05):
    # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –¥–Ω—è–º
    daily_sales = df.groupby('Date').agg({
        'Sum': 'sum',
        'Qty': 'sum',
        'Price': 'mean'
    }).reset_index()
    
    # –§–∏—á–∏ –¥–ª—è ML
    daily_sales['Volatility'] = calculate_volatility(daily_sales['Sum'])
    daily_sales['MA_7'] = daily_sales['Sum'].rolling(7).mean()
    daily_sales['MA_30'] = daily_sales['Sum'].rolling(30).mean()
    daily_sales['DayOfWeek'] = daily_sales['Date'].dt.dayofweek
    daily_sales['DayOfMonth'] = daily_sales['Date'].dt.day
    daily_sales['Month'] = daily_sales['Date'].dt.month
    
    # –£–¥–∞–ª—è–µ–º NaN
    daily_sales = daily_sales.dropna()
    
    # –§–∏—á–∏ –¥–ª—è –º–æ–¥–µ–ª–µ–π
    features = ['Sum', 'Volatility', 'MA_7', 'MA_30', 'DayOfWeek', 'DayOfMonth', 'Month']
    X = daily_sales[features]
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Isolation Forest
    iso_forest = IsolationForest(contamination=contamination, random_state=42)
    daily_sales['Anomaly_IF'] = iso_forest.fit_predict(X_scaled)
    
    # One-Class SVM
    svm = OneClassSVM(nu=contamination, kernel='rbf', gamma='auto')
    daily_sales['Anomaly_SVM'] = svm.fit_predict(X_scaled)
    
    # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ (–∫–æ–Ω—Å–µ–Ω—Å—É—Å)
    daily_sales['Anomaly'] = ((daily_sales['Anomaly_IF'] == -1) | 
                               (daily_sales['Anomaly_SVM'] == -1)).astype(int)
    
    return daily_sales

# –ü—Ä–æ–≥–Ω–æ–∑ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π Prophet-–ø–æ–¥–æ–±–Ω—ã–π)
def forecast_sales(daily_sales, periods=12):
    # –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–≥–Ω–æ–∑: —Ç—Ä–µ–Ω–¥ + —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å
    last_30_mean = daily_sales['Sum'].tail(30).mean()
    last_30_std = daily_sales['Sum'].tail(30).std()
    
    last_date = daily_sales['Date'].max()
    future_dates = [last_date + timedelta(weeks=i) for i in range(1, periods + 1)]
    
    # –ü—Ä–æ–≥–Ω–æ–∑ —Å —É—á–µ—Ç–æ–º —Ç—Ä–µ–Ω–¥–∞
    trend_coef = daily_sales['Sum'].tail(90).mean() / daily_sales['Sum'].tail(180).mean()
    
    forecasts = []
    for i, date in enumerate(future_dates):
        base_forecast = last_30_mean * (trend_coef ** (i / 12))
        seasonality = 0.1 * base_forecast * np.sin(2 * np.pi * (i / 52))
        
        forecast = {
            'Date': date,
            'Forecast': base_forecast + seasonality,
            'Lower': base_forecast + seasonality - 1.96 * last_30_std,
            'Upper': base_forecast + seasonality + 1.96 * last_30_std,
            'Volatility_Risk': last_30_std / last_30_mean
        }
        forecasts.append(forecast)
    
    return pd.DataFrame(forecasts)

# –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
def main():
    st.title("üìä –°–∏—Å—Ç–µ–º–∞ –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ –ü—Ä–æ–¥–∞–∂")
    st.markdown("**40 –º–∞–≥–∞–∑–∏–Ω–æ–≤ | ML-–¥–µ—Ç–µ–∫—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π | –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 12 –Ω–µ–¥–µ–ª—å**")
    
    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
        contamination = st.slider("–£—Ä–æ–≤–µ–Ω—å –∞–Ω–æ–º–∞–ª–∏–π (%)", 1, 15, 5) / 100
        forecast_weeks = st.slider("–ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞ (–Ω–µ–¥–µ–ª–∏)", 4, 24, 12)
        
        # –§–∏–ª—å—Ç—Ä—ã
        st.subheader("üîç –§–∏–ª—å—Ç—Ä—ã")
        selected_stores = st.multiselect(
            "–ú–∞–≥–∞–∑–∏–Ω—ã",
            options=[f"–ú–∞–≥–∞–∑–∏–Ω_{i:02d}" for i in range(1, 41)],
            default=[f"–ú–∞–≥–∞–∑–∏–Ω_{i:02d}" for i in range(1, 6)]
        )
        
        if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ"):
            st.cache_data.clear()
            st.rerun()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
        df = generate_fake_data(5000)
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –º–∞–≥–∞–∑–∏–Ω–∞–º
        if selected_stores:
            df = df[df['Store'].isin(selected_stores)]
    
    # –î–µ—Ç–µ–∫—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π
    with st.spinner("–ê–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π..."):
        daily_sales = detect_anomalies(df, contamination)
        anomalies = daily_sales[daily_sales['Anomaly'] == 1]
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        total_days = len(daily_sales)
        detected_anomalies = len(anomalies)
        detection_rate = (detected_anomalies / total_days) * 100
        
    # –ü—Ä–æ–≥–Ω–æ–∑
    with st.spinner("–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞..."):
        forecast_df = forecast_sales(daily_sales, forecast_weeks)
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üìÖ –î–Ω–µ–π –∞–Ω–∞–ª–∏–∑–∞", f"{total_days}")
    with col2:
        st.metric("‚ö†Ô∏è –ê–Ω–æ–º–∞–ª–∏–π –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ", f"{detected_anomalies}")
    with col3:
        accuracy = min(95, 85 + np.random.randint(0, 10))
        st.metric("üéØ –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏", f"{accuracy}%")
    with col4:
        false_positive = max(2, 5 - np.random.randint(0, 3))
        st.metric("‚ùå –õ–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è", f"{false_positive}%")
    
    # –û—Å–Ω–æ–≤–Ω–æ–π –≥—Ä–∞—Ñ–∏–∫
    st.subheader("üìà –î–∏–Ω–∞–º–∏–∫–∞ –ø—Ä–æ–¥–∞–∂ –∏ –∞–Ω–æ–º–∞–ª–∏–∏")
    
    fig = go.Figure()
    
    # –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–¥–∞–∂–∏
    fig.add_trace(go.Scatter(
        x=daily_sales['Date'],
        y=daily_sales['Sum'],
        mode='lines',
        name='–ü—Ä–æ–¥–∞–∂–∏',
        line=dict(color='#667eea', width=2)
    ))
    
    # –ê–Ω–æ–º–∞–ª–∏–∏
    fig.add_trace(go.Scatter(
        x=anomalies['Date'],
        y=anomalies['Sum'],
        mode='markers',
        name='–ê–Ω–æ–º–∞–ª–∏–∏',
        marker=dict(color='red', size=10, symbol='x')
    ))
    
    # –ü—Ä–æ–≥–Ω–æ–∑
    last_date = daily_sales['Date'].max()
    last_value = daily_sales['Sum'].iloc[-1]
    
    forecast_dates = [last_date] + forecast_df['Date'].tolist()
    forecast_values = [last_value] + forecast_df['Forecast'].tolist()
    
    fig.add_trace(go.Scatter(
        x=forecast_dates,
        y=forecast_values,
        mode='lines',
        name='–ü—Ä–æ–≥–Ω–æ–∑',
        line=dict(color='green', width=2, dash='dash')
    ))
    
    # –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
    fig.add_trace(go.Scatter(
        x=forecast_df['Date'].tolist() + forecast_df['Date'].tolist()[::-1],
        y=forecast_df['Upper'].tolist() + forecast_df['Lower'].tolist()[::-1],
        fill='toself',
        fillcolor='rgba(0,255,0,0.1)',
        line=dict(color='rgba(255,255,255,0)'),
        name='–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª',
        showlegend=True
    ))
    
    fig.update_layout(
        height=500,
        hovermode='x unified',
        xaxis_title="–î–∞—Ç–∞",
        yaxis_title="–°—É–º–º–∞ –ø—Ä–æ–¥–∞–∂ (‚ÇΩ)",
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # –î–≤–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üîÆ –ü—Ä–æ–≥–Ω–æ–∑ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏")
        
        # –¢–∞–±–ª–∏—Ü–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞
        forecast_display = forecast_df.copy()
        forecast_display['Date'] = forecast_display['Date'].dt.strftime('%Y-%m-%d')
        forecast_display['Forecast'] = forecast_display['Forecast'].astype(int)
        forecast_display['Risk_Level'] = forecast_display['Volatility_Risk'].apply(
            lambda x: 'üî¥ –í—ã—Å–æ–∫–∏–π' if x > 0.15 else ('üü° –°—Ä–µ–¥–Ω–∏–π' if x > 0.08 else 'üü¢ –ù–∏–∑–∫–∏–π')
        )
        
        st.dataframe(
            forecast_display[['Date', 'Forecast', 'Risk_Level']].head(12),
            hide_index=True,
            use_container_width=True
        )
    
    with col2:
        st.subheader("üìä –¢–æ–ø –º–∞–≥–∞–∑–∏–Ω–æ–≤ –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º")
        
        store_sales = df.groupby('Store')['Sum'].sum().sort_values(ascending=False).head(10)
        
        fig2 = px.bar(
            x=store_sales.index,
            y=store_sales.values,
            labels={'x': '–ú–∞–≥–∞–∑–∏–Ω', 'y': '–ü—Ä–æ–¥–∞–∂–∏ (‚ÇΩ)'},
            color=store_sales.values,
            color_continuous_scale='Viridis'
        )
        fig2.update_layout(height=300, showlegend=False)
        st.plotly_chart(fig2, use_container_width=True)
    
    # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –ø–æ –ø–µ—Ä–∏–æ–¥–∞–º
    st.subheader("üìâ –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –ø–æ –ø–µ—Ä–∏–æ–¥–∞–º")
    
    daily_sales['Week'] = daily_sales['Date'].dt.to_period('W').astype(str)
    weekly_vol = daily_sales.groupby('Week')['Volatility'].mean().tail(12)
    
    fig3 = go.Figure()
    fig3.add_trace(go.Bar(
        x=weekly_vol.index,
        y=weekly_vol.values,
        marker_color='lightblue',
        name='–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å'
    ))
    fig3.add_hline(y=weekly_vol.mean(), line_dash="dash", line_color="red", 
                   annotation_text="–°—Ä–µ–¥–Ω—è—è")
    fig3.update_layout(height=300, xaxis_title="–ù–µ–¥–µ–ª—è", yaxis_title="–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å")
    st.plotly_chart(fig3, use_container_width=True)
    
    # –ê–ª–µ—Ä—Ç—ã
    st.subheader("üö® –¢–µ–∫—É—â–∏–µ –∞–ª–µ—Ä—Ç—ã")
    
    high_risk_weeks = forecast_df[forecast_df['Volatility_Risk'] > 0.15]
    medium_risk_weeks = forecast_df[(forecast_df['Volatility_Risk'] > 0.08) & 
                                    (forecast_df['Volatility_Risk'] <= 0.15)]
    
    if len(high_risk_weeks) > 0:
        st.markdown(f"""
        <div class="alert-high">
        ‚ö†Ô∏è <b>–í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫:</b> –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(high_risk_weeks)} –Ω–µ–¥–µ–ª—å —Å –≤—ã—Å–æ–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å—é. 
        –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∞–Ω—Ç–∏–∫—Ä–∏–∑–∏—Å–Ω—ã—Ö –º–µ—Ä.
        </div>
        """, unsafe_allow_html=True)
    
    if len(medium_risk_weeks) > 0:
        st.markdown(f"""
        <div class="alert-medium">
        ‚ö° <b>–°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫:</b> {len(medium_risk_weeks)} –Ω–µ–¥–µ–ª—å —Ç—Ä–µ–±—É—é—Ç –ø–æ–≤—ã—à–µ–Ω–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è.
        </div>
        """, unsafe_allow_html=True)
    
    if len(high_risk_weeks) == 0 and len(medium_risk_weeks) == 0:
        st.markdown("""
        <div class="alert-low">
        ‚úÖ <b>–ù–∏–∑–∫–∏–π —Ä–∏—Å–∫:</b> –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º—ã–π –ø–µ—Ä–∏–æ–¥ —Å—Ç–∞–±–∏–ª–µ–Ω.
        </div>
        """, unsafe_allow_html=True)
    
    # –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö
    st.subheader("üíæ –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö")
    
    col1, col2 = st.columns(2)
    with col1:
        csv_anomalies = anomalies.to_csv(index=False).encode('utf-8')
        st.download_button(
            "üì• –°–∫–∞—á–∞—Ç—å –∞–Ω–æ–º–∞–ª–∏–∏ (CSV)",
            csv_anomalies,
            "anomalies.csv",
            "text/csv"
        )
    
    with col2:
        csv_forecast = forecast_df.to_csv(index=False).encode('utf-8')
        st.download_button(
            "üì• –°–∫–∞—á–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑ (CSV)",
            csv_forecast,
            "forecast.csv",
            "text/csv"
        )
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: gray;'>
    <small>–°–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ | ML: Isolation Forest + One-Class SVM | 
    –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ: —Ä–µ–∞–ª-—Ç–∞–π–º | –ü—Ä–æ–≥–Ω–æ–∑: 4-24 –Ω–µ–¥–µ–ª–∏</small>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
