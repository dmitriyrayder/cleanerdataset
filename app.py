import streamlit as st
import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
from st_aggrid import AgGrid, GridOptionsBuilder, JsCode, GridUpdateMode
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import re

st.set_page_config(page_title="üìä –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞ —Å AgGrid", layout="wide")
st.title("üß† ML + AgGrid: –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö")

# === –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö ===
def validate_email(email):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ email"""
    if pd.isna(email):
        return False
    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    return bool(re.match(pattern, str(email)))

def validate_phone(phone):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ —Ç–µ–ª–µ—Ñ–æ–Ω–∞"""
    if pd.isna(phone):
        return False
    # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ü–∏—Ñ—Ä—ã –∏ –¥–ª–∏–Ω—É
    cleaned = re.sub(r'[^\d]', '', str(phone))
    return len(cleaned) >= 10 and len(cleaned) <= 15

def detect_outliers_iqr(series):
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ –º–µ—Ç–æ–¥–æ–º IQR"""
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return (series < lower_bound) | (series > upper_bound)

def analyze_text_quality(series):
    """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    results = {}
    results['null_count'] = series.isnull().sum()
    results['empty_count'] = (series == '').sum()
    results['whitespace_only'] = series.str.strip().eq('').sum() if series.dtype == 'object' else 0
    results['unique_count'] = series.nunique()
    results['duplicate_count'] = series.duplicated().sum()
    results['min_length'] = series.str.len().min() if series.dtype == 'object' else None
    results['max_length'] = series.str.len().max() if series.dtype == 'object' else None
    results['avg_length'] = series.str.len().mean() if series.dtype == 'object' else None
    return results

def create_data_quality_report(df):
    """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö"""
    report = {}
    
    # –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    report['total_rows'] = len(df)
    report['total_columns'] = len(df.columns)
    report['memory_usage'] = df.memory_usage(deep=True).sum() / 1024**2  # MB
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º –¥–∞–Ω–Ω—ã—Ö
    report['data_types'] = df.dtypes.value_counts().to_dict()
    
    # –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    report['missing_values'] = df.isnull().sum().to_dict()
    report['missing_percentage'] = (df.isnull().sum() / len(df) * 100).to_dict()
    
    # –î—É–±–ª–∏–∫–∞—Ç—ã
    report['duplicate_rows'] = df.duplicated().sum()
    report['duplicate_percentage'] = df.duplicated().sum() / len(df) * 100
    
    return report

# === –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ ===
uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel-—Ñ–∞–π–ª", type=["xlsx", "xls", "csv"])

if uploaded_file:
    try:
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        else:
            df = pd.read_excel(uploaded_file)
        
        # –ü–æ–ø—ã—Ç–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç
        date_columns = ['Datasales'] if 'Datasales' in df.columns else []
        for col in date_columns:
            try:
                df[col] = pd.to_datetime(df[col], errors='coerce')
            except:
                st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É {col} –≤ –¥–∞—Ç—É")
        
        st.success("‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
        
        # === –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –ê–ù–ê–õ–ò–¢–ò–ö–ê –î–ê–¢–ê–°–ï–¢–ê ===
        st.header("üìà –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö
        quality_report = create_data_quality_report(df)
        
        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("üìä –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫", quality_report['total_rows'])
        with col2:
            st.metric("üìã –í—Å–µ–≥–æ –∫–æ–ª–æ–Ω–æ–∫", quality_report['total_columns'])
        with col3:
            st.metric("üíæ –†–∞–∑–º–µ—Ä –≤ –ø–∞–º—è—Ç–∏", f"{quality_report['memory_usage']:.2f} MB")
        with col4:
            st.metric("üîÑ –î—É–±–ª–∏–∫–∞—Ç—ã", f"{quality_report['duplicate_rows']} ({quality_report['duplicate_percentage']:.1f}%)")
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º
        st.subheader("üîç –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º")
        
        column_analysis = []
        for col in df.columns:
            analysis = {
                '–ö–æ–ª–æ–Ω–∫–∞': col,
                '–¢–∏–ø –¥–∞–Ω–Ω—ã—Ö': str(df[col].dtype),
                '–ü—Ä–æ–ø—É—â–µ–Ω–æ': df[col].isnull().sum(),
                '–ü—Ä–æ–ø—É—â–µ–Ω–æ %': f"{df[col].isnull().sum() / len(df) * 100:.1f}%",
                '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö': df[col].nunique(),
                '–î—É–±–ª–∏–∫–∞—Ç–æ–≤': df[col].duplicated().sum(),
            }
            
            if df[col].dtype in ['int64', 'float64']:
                analysis['–ú–∏–Ω'] = df[col].min()
                analysis['–ú–∞–∫—Å'] = df[col].max()
                analysis['–°—Ä–µ–¥–Ω–µ–µ'] = f"{df[col].mean():.2f}"
                analysis['–ú–µ–¥–∏–∞–Ω–∞'] = f"{df[col].median():.2f}"
                analysis['–°—Ç–¥. –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ'] = f"{df[col].std():.2f}"
            elif df[col].dtype == 'object':
                analysis['–ú–∏–Ω –¥–ª–∏–Ω–∞'] = df[col].str.len().min() if not df[col].empty else 0
                analysis['–ú–∞–∫—Å –¥–ª–∏–Ω–∞'] = df[col].str.len().max() if not df[col].empty else 0
                analysis['–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞'] = f"{df[col].str.len().mean():.1f}" if not df[col].empty else "0"
                analysis['–ü—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏'] = (df[col] == '').sum()
            
            column_analysis.append(analysis)
        
        analysis_df = pd.DataFrame(column_analysis)
        st.dataframe(analysis_df, use_container_width=True)
        
        # === –ü–†–û–í–ï–†–ö–ò –ö–ê–ß–ï–°–¢–í–ê –î–ê–ù–ù–´–• ===
        st.header("üîç –ü—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        required_columns = ['Magazin', 'Datasales', 'Describe', 'Model', 'Segment', 'Price', 'Qty', 'Sum']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            st.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(missing_columns)}")
        else:
            st.success("‚úÖ –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
        
        # --- –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ ---
        if all(col in df.columns for col in ['Price', 'Qty', 'Sum']):
            df['calc_sum'] = df['Price'] * df['Qty']
            df['sum_diff'] = np.abs(df['calc_sum'] - df['Sum'])
            df['error_sum'] = df['sum_diff'] > 1e-2
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            df['negative_price'] = df['Price'] < 0
            df['negative_qty'] = df['Qty'] < 0
            df['negative_sum'] = df['Sum'] < 0
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω—É–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            df['zero_price'] = df['Price'] == 0
            df['zero_qty'] = df['Qty'] == 0
            df['zero_sum'] = df['Sum'] == 0
            
            st.subheader("üßÆ –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("‚ùå –û—à–∏–±–∫–∏ —Å—É–º–º—ã", df['error_sum'].sum())
                st.metric("‚ûñ –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ —Ü–µ–Ω—ã", df['negative_price'].sum())
            with col2:
                st.metric("‚ûñ –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞", df['negative_qty'].sum())
                st.metric("‚ûñ –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ —Å—É–º–º—ã", df['negative_sum'].sum())
            with col3:
                st.metric("0Ô∏è‚É£ –ù—É–ª–µ–≤—ã–µ —Ü–µ–Ω—ã", df['zero_price'].sum())
                st.metric("0Ô∏è‚É£ –ù—É–ª–µ–≤—ã–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞", df['zero_qty'].sum())
        
        # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç ---
        if 'Datasales' in df.columns:
            st.subheader("üìÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –±—É–¥—É—â–∏–µ –¥–∞—Ç—ã
            today = datetime.now()
            df['future_date'] = df['Datasales'] > today
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª–∏—à–∫–æ–º —Å—Ç–∞—Ä—ã–µ –¥–∞—Ç—ã
            old_threshold = today - timedelta(days=365*10)  # 10 –ª–µ—Ç –Ω–∞–∑–∞–¥
            df['too_old_date'] = df['Datasales'] < old_threshold
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞—Ç—ã
            df['invalid_date'] = df['Datasales'].isnull()
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("üîÆ –ë—É–¥—É—â–∏–µ –¥–∞—Ç—ã", df['future_date'].sum())
            with col2:
                st.metric("üìú –°–ª–∏—à–∫–æ–º —Å—Ç–∞—Ä—ã–µ –¥–∞—Ç—ã", df['too_old_date'].sum())
            with col3:
                st.metric("‚ùå –ù–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞—Ç—ã", df['invalid_date'].sum())
        
        # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–ª–µ–π ---
        st.subheader("üìù –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–ª–µ–π")
        text_columns = ['Magazin', 'Describe', 'Model', 'Segment']
        
        for col in text_columns:
            if col in df.columns:
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
                df[f'{col}_suspicious_chars'] = df[col].str.contains(r'[<>{}[\]\\|`~]', na=False)
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ/–¥–ª–∏–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
                df[f'{col}_too_short'] = df[col].str.len() < 2
                df[f'{col}_too_long'] = df[col].str.len() > 100
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã (–ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–ª–µ–π)
                df[f'{col}_only_digits'] = df[col].str.isdigit()
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric(f"‚ùå {col}: –ø—Ä–æ–ø—É—â–µ–Ω–æ", df[col].isnull().sum())
                with col2:
                    st.metric(f"‚ö†Ô∏è {col}: –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã", df[f'{col}_suspicious_chars'].sum())
                with col3:
                    st.metric(f"üìè {col}: —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ", df[f'{col}_too_short'].sum())
                with col4:
                    st.metric(f"üî¢ {col}: —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã", df[f'{col}_only_digits'].sum())
        
        # --- –ü–æ–∏—Å–∫ –∞–Ω–æ–º–∞–ª–∏–π —Å –ø–æ–º–æ—â—å—é ML ---
        st.subheader("ü§ñ ML-–∞–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π")
        
        numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
        if len(numeric_columns) >= 2:
            try:
                # –£–¥–∞–ª—è–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–æ–≤–µ—Ä–æ–∫ –¥–ª—è ML –∞–Ω–∞–ª–∏–∑–∞
                ml_columns = [col for col in numeric_columns if not col.startswith(('calc_', 'sum_', 'error_', 'negative_', 'zero_'))]
                
                if len(ml_columns) >= 2:
                    X = df[ml_columns].fillna(0)
                    X_scaled = StandardScaler().fit_transform(X)
                    
                    # Isolation Forest
                    iso = IsolationForest(contamination=0.05, random_state=42)
                    df['ml_anomaly'] = iso.fit_predict(X_scaled) == -1
                    
                    # IQR outliers –¥–ª—è —á–∏—Å–ª–µ–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
                    for col in ml_columns:
                        if col in ['Price', 'Qty', 'Sum']:
                            df[f'{col}_outlier_iqr'] = detect_outliers_iqr(df[col])
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("üö® ML-–∞–Ω–æ–º–∞–ª–∏–∏", df['ml_anomaly'].sum())
                    with col2:
                        if 'Price_outlier_iqr' in df.columns:
                            total_iqr_outliers = (df['Price_outlier_iqr'] | 
                                                df['Qty_outlier_iqr'] | 
                                                df['Sum_outlier_iqr']).sum()
                            st.metric("üìä IQR-–≤—ã–±—Ä–æ—Å—ã", total_iqr_outliers)
                    
                    st.success("‚úÖ ML-–∞–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                else:
                    st.warning("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∏—Å–ª–µ–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è ML-–∞–Ω–∞–ª–∏–∑–∞")
                    df['ml_anomaly'] = False
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ ML-–∞–Ω–∞–ª–∏–∑–∞: {e}")
                df['ml_anomaly'] = False
        else:
            st.warning("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∏—Å–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML-–∞–Ω–∞–ª–∏–∑–∞")
            df['ml_anomaly'] = False
        
        # --- –°–≤–æ–¥–∫–∞ –ø–æ –≤—Å–µ–º –ø—Ä–æ–±–ª–µ–º–∞–º ---
        st.subheader("üìã –°–≤–æ–¥–∫–∞ –ø–æ –ø—Ä–æ–±–ª–µ–º–∞–º")
        
        # –ü–æ–¥—Å—á–µ—Ç –≤—Å–µ—Ö –ø—Ä–æ–±–ª–µ–º
        problem_columns = [col for col in df.columns if any(keyword in col for keyword in 
                          ['error_', 'negative_', 'zero_', 'future_', 'too_old_', 'invalid_', 
                           'suspicious_', 'too_short_', 'too_long_', 'only_digits_', 'ml_anomaly', 'outlier_'])]
        
        if problem_columns:
            df['total_problems'] = df[problem_columns].sum(axis=1)
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("üìä –°—Ç—Ä–æ–∫ —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏", (df['total_problems'] > 0).sum())
            with col2:
                st.metric("‚úÖ –ß–∏—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫", (df['total_problems'] == 0).sum())
            with col3:
                st.metric("üìà –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö", f"{(df['total_problems'] == 0).sum() / len(df) * 100:.1f}%")
        
        # --- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–±–ª–µ–º ---
        if problem_columns:
            st.subheader("üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–±–ª–µ–º")
            
            # –ì—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º
            problem_counts = df[problem_columns].sum().sort_values(ascending=True)
            
            fig = px.bar(
                x=problem_counts.values,
                y=problem_counts.index,
                orientation='h',
                title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –ø—Ä–æ–±–ª–µ–º –≤ –¥–∞–Ω–Ω—ã—Ö",
                labels={'x': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–±–ª–µ–º', 'y': '–¢–∏–ø –ø—Ä–æ–±–ª–µ–º—ã'}
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # === AgGrid: –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ===
        st.header("üìã –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö")
        
        gb = GridOptionsBuilder.from_dataframe(df)
        gb.configure_default_column(editable=True, filter=True, sortable=True, resizable=True)
        
        # –£–ª—É—á—à–µ–Ω–Ω–∞—è —É—Å–ª–æ–≤–Ω–∞—è —Ä–∞—Å–∫—Ä–∞—Å–∫–∞
        cell_style_jscode = JsCode("""
        function(params) {
            const data = params.data;
            let backgroundColor = null;
            
            // –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ - –∫—Ä–∞—Å–Ω—ã–π
            if (data.error_sum || data.negative_price || data.negative_qty || data.negative_sum) {
                backgroundColor = '#ffcccc';
            }
            // ML –∞–Ω–æ–º–∞–ª–∏–∏ - –∂–µ–ª—Ç—ã–π
            else if (data.ml_anomaly) {
                backgroundColor = '#ffffcc';
            }
            // –ü—Ä–æ–±–ª–µ–º—ã —Å –¥–∞—Ç–∞–º–∏ - –æ—Ä–∞–Ω–∂–µ–≤—ã–π
            else if (data.future_date || data.too_old_date || data.invalid_date) {
                backgroundColor = '#ffe6cc';
            }
            // –ü—Ä–æ–±–ª–µ–º—ã —Å —Ç–µ–∫—Å—Ç–æ–º - –≥–æ–ª—É–±–æ–π
            else if (data.Magazin_suspicious_chars || data.Describe_suspicious_chars || 
                     data.Model_suspicious_chars || data.Segment_suspicious_chars) {
                backgroundColor = '#cce6ff';
            }
            // –í—ã–±—Ä–æ—Å—ã - —Ä–æ–∑–æ–≤—ã–π
            else if (data.Price_outlier_iqr || data.Qty_outlier_iqr || data.Sum_outlier_iqr) {
                backgroundColor = '#ffccff';
            }
            
            return backgroundColor ? { backgroundColor: backgroundColor } : null;
        }
        """)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç–∏–ª–∏ –∫ –æ—Å–Ω–æ–≤–Ω—ã–º –∫–æ–ª–æ–Ω–∫–∞–º
        main_columns = ['Magazin', 'Datasales', 'Describe', 'Model', 'Segment', 'Price', 'Qty', 'Sum']
        for col in main_columns:
            if col in df.columns:
                gb.configure_column(col, cellStyle=cell_style_jscode)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        boolean_columns = [col for col in df.columns if df[col].dtype == 'bool']
        for col in boolean_columns:
            gb.configure_column(col, type=["booleanColumn"], editable=False)
        
        gb.configure_grid_options(domLayout='normal', pagination=True, paginationPageSize=50)
        gb.configure_selection(selection_mode="multiple", use_checkbox=True)
        
        grid_options = gb.build()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ª–µ–≥–µ–Ω–¥—É –¥–ª—è —Ü–≤–µ—Ç–æ–≤
        st.markdown("""
        **–õ–µ–≥–µ–Ω–¥–∞ —Ü–≤–µ—Ç–æ–≤:**
        - üî¥ –ö—Ä–∞—Å–Ω—ã–π: –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ (–Ω–µ–≤–µ—Ä–Ω—ã–µ —Å—É–º–º—ã, –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
        - üü° –ñ–µ–ª—Ç—ã–π: ML-–∞–Ω–æ–º–∞–ª–∏–∏
        - üü† –û—Ä–∞–Ω–∂–µ–≤—ã–π: –ø—Ä–æ–±–ª–µ–º—ã —Å –¥–∞—Ç–∞–º–∏
        - üîµ –ì–æ–ª—É–±–æ–π: –ø—Ä–æ–±–ª–µ–º—ã —Å —Ç–µ–∫—Å—Ç–æ–º
        - üü£ –†–æ–∑–æ–≤—ã–π: —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –≤—ã–±—Ä–æ—Å—ã
        """)
        
        grid_response = AgGrid(
            df,
            gridOptions=grid_options,
            height=600,
            width='100%',
            update_mode=GridUpdateMode.VALUE_CHANGED,
            fit_columns_on_grid_load=True,
            allow_unsafe_jscode=True,
            theme="alpine",
            enable_enterprise_modules=True
        )
        
        updated_df = pd.DataFrame(grid_response['data'])
        
        # === –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö ===
        st.header("üì§ –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # –≠–∫—Å–ø–æ—Ä—Ç –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
            csv_all = updated_df.to_csv(index=False)
            st.download_button(
                "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ (CSV)",
                csv_all,
                file_name="all_data_with_quality_checks.csv",
                mime="text/csv"
            )
        
        with col2:
            # –≠–∫—Å–ø–æ—Ä—Ç —Ç–æ–ª—å–∫–æ —á–∏—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if 'total_problems' in updated_df.columns:
                clean_data = updated_df[updated_df['total_problems'] == 0]
                main_cols = [col for col in main_columns if col in clean_data.columns]
                clean_export = clean_data[main_cols]
                
                csv_clean = clean_export.to_csv(index=False)
                st.download_button(
                    "‚úÖ –°–∫–∞—á–∞—Ç—å —á–∏—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ (CSV)",
                    csv_clean,
                    file_name="clean_data_only.csv",
                    mime="text/csv"
                )
        
        with col3:
            # –≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–±–ª–µ–º–∞—Ö
            if problem_columns:
                problem_data = updated_df[updated_df['total_problems'] > 0]
                if not problem_data.empty:
                    csv_problems = problem_data.to_csv(index=False)
                    st.download_button(
                        "‚ö†Ô∏è –°–∫–∞—á–∞—Ç—å –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (CSV)",
                        csv_problems,
                        file_name="problem_data.csv",
                        mime="text/csv"
                    )
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        st.subheader("üìä –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–æ–∫", len(updated_df))
        with col2:
            if 'total_problems' in updated_df.columns:
                clean_count = (updated_df['total_problems'] == 0).sum()
                st.metric("‚úÖ –ß–∏—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫", clean_count)
        with col3:
            if 'total_problems' in updated_df.columns:
                problem_count = (updated_df['total_problems'] > 0).sum()
                st.metric("‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å—Ç—Ä–æ–∫", problem_count)
        with col4:
            if 'total_problems' in updated_df.columns:
                quality_score = (updated_df['total_problems'] == 0).sum() / len(updated_df) * 100
                st.metric("üéØ –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞", f"{quality_score:.1f}%")
        
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {e}")
        st.stop()

else:
    st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel –∏–ª–∏ CSV —Ñ–∞–π–ª –¥–ª—è –Ω–∞—á–∞–ª–∞ –∞–Ω–∞–ª–∏–∑–∞")
    st.markdown("""
    **–û–∂–∏–¥–∞–µ–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏:**
    - `Magazin` - –Ω–∞–∑–≤–∞–Ω–∏–µ –º–∞–≥–∞–∑–∏–Ω–∞
    - `Datasales` - –¥–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏
    - `Art` - –∞—Ä—Ç–∏–∫—É–ª (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    - `Describe` - –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
    - `Model` - –º–æ–¥–µ–ª—å —Ç–æ–≤–∞—Ä–∞
    - `Segment` - —Å–µ–≥–º–µ–Ω—Ç —Ç–æ–≤–∞—Ä–∞
    - `Price` - —Ü–µ–Ω–∞ –∑–∞ –µ–¥–∏–Ω–∏—Ü—É
    - `Qty` - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    - `Sum` - –æ–±—â–∞—è —Å—É–º–º–∞
    """)
